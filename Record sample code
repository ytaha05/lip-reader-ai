# pip install streamlit opencv-python mediapipe numpy

import cv2
import mediapipe as mp
import streamlit as st
import numpy as np
import os
import time

st.title("SilentAid â€“ Lip Detection & Data Collection")

# Initialize MediaPipe
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False,
                                   max_num_faces=1,
                                   refine_landmarks=True,
                                   min_detection_confidence=0.5,
                                   min_tracking_confidence=0.5)

# Webcam setup
run = st.checkbox('Start Camera')
FRAME_WINDOW = st.image([])

label = st.text_input("Enter word you're mouthing (e.g., 'help'):")
record = st.checkbox("Record Sequence")
save_button = st.button("Save Sequence")
status = st.empty()

sequence = []
os.makedirs("lip_data", exist_ok=True)

cap = cv2.VideoCapture(0)

LIPS_LANDMARKS = set()
for pair in mp_face_mesh.FACEMESH_LIPS:
    LIPS_LANDMARKS.update(pair)

while run:
    success, frame = cap.read()
    if not success:
        st.warning("Webcam not detected.")
        break

    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb)

    if results.multi_face_landmarks:
        for face_landmarks in results.multi_face_landmarks:
            h, w, _ = frame.shape
            lip_points = []

            for idx in LIPS_LANDMARKS:
                x = int(face_landmarks.landmark[idx].x * w)
                y = int(face_landmarks.landmark[idx].y * h)
                lip_points.append((x, y))
                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)

            if lip_points:
                lip_np = np.array(lip_points)
                x, y, w_lip, h_lip = cv2.boundingRect(lip_np)
                cv2.rectangle(frame, (x, y), (x + w_lip, y + h_lip), (0, 0, 255), 1)

                if record and label:
                    sequence.append(lip_points)
                    status.info(f"Recording... {len(sequence)} frames")

    FRAME_WINDOW.image(frame, channels="BGR")

    if save_button and sequence and label:
        filename = f"lip_data/{label}_{int(time.time())}.npy"
        np.save(filename, np.array(sequence))
        status.success(f"Saved {len(sequence)} frames as {filename}")
        sequence = []

cap.release()
